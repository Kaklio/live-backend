// import { InferenceClient } from "@huggingface/inference";

// const client = new InferenceClient(process.env.HF_TOKEN);

// const chatCompletion = await client.chatCompletion({
//   model: "openai/gpt-oss-120b:fastest",
//   messages: [
//     {
//       role: "user",
//       content: "How many 'G's in 'huggingface'?",
//     },
//   ],
// });

// console.log(chatCompletion.choices[0].message);